

# 数据迁移及相关工具介绍



## 数据迁移方案

**本文讨论的是从TDengine 1.6xx版升级并迁移到TDengine 2.0xx版的情形。**

考虑到1.6版的更改默认端口后，不能支持集群，故迁移过程统一在docker环境下进行。

本文的预设条件是：

v1.6为待升级、迁移的环境，由双机集群组成，private/public IP相同，分别为：192.168.1.101、192.168.1.102；其中间迁移环境IP为：10.0.0.81、10.0.0.82

v2.0为升级、迁移后的环境，双机集群，fqdn分别为：td1、td2；其中间迁移环境fqdn为：tdmi1、tdmi2

以上述案例为例，结合下文的升级计划，本文阐述的迁移过程共需创建docker环境如下：

1. 测试B1：1.6版TDengine双节点集群，导出数据用。docker容器：td1.6_node1/2/...n

2. 测试B：2.0版TDengine双节点集群，导入数据用。docker容器：td2.0_node1/2/...n

3. td_dump_node：用于运行taosDumpTunnel，将1.6数据转移至2.0。docker容器：td_dump_node

4. 测试C：2.0版TDengine双节点集群，测试验证用。

【提示】为提升工作效率，建议将测试B与B1分别部署在不同的物理机上，充分利用网络带宽，减轻单机磁盘IO的负担，加快数据迁移速度。



#### 制订升级计划

1. 生产环境将保留1.6版，与2.0版并行运行一段时间，时长待定。提前与客户确认其TDengine仅保存时序数据，不会回写汇总数据
2. 在测试环境上部署Docker双节点集群1.6系统，为**测试B1**
3. 在测试环境上部署Docker双节点集群2.0系统，为**测试B**
4. 将**1.6生产数据**打包，复制一份到**测试B1**，将数据平行迁移至测试B1【taosmigrate16】，导出全表表结构schema【taosdump16】
5. 验证**测试B**环境无误，导入全表表结构【taosdump20】，并确认准确、完整
6. 在数据迁移节点上(dockers: taos_dump_node)，将**测试B1数据迁移至测试B**【taosDumpTunnel】
7. 确认迁移至测试B之2.0数据与测试B1表数、记录数相符，检查基本功能、性能是否正常，做好记录。如不相符，或有疑问，提出jira向研发团队求助，直至解决 
8. 将**测试B**上的2.0迁移完成后的数据打包，备份留存
9. 重新部署2.0静态版双节点集群**测试C**，将第8步的2.0数据解包、导入测试C，将数据平行迁移至**测试C**【taosmigrate20】
10. 在**测试C**上启动服务，记录taosd服务启动时长
11. 在**测试C**上升级客户端，进行全业务验证：采集入库、查询、报表统计等
12. 在生产服务器上部署2.0静态版双节点集群 - **生产B**，将第8步的2.0数据导入**生产B**，完成数据平行迁移【taosmigrate20】
13. 在**生产B**上启动服务【start-taosd.sh】，客户端割接指向**生产B**
14. 导入数据差额：将第4步到第13步期间**生产B**缺少的数据，从生产A导出，转换后导入生产B
15. ≤ 原1.6版**生产A**继续保持运行，数据采集kafka队列同时向生产A和生产B写入，生产A作为回退方案
16. 生产A与生产B并行运行一段时间后，确认2.0版已稳定运行，停生产A，将**生产B**升级至正式版

tar打包 - taosdump v1.6导出所有表结构schema，sql - 编辑docker-compose.yml - 启动v2.0容器集群，创建表结构



## 涛思工具

#### taosdump v1.6

**该工具建议运行在td_dump_node的dockers容器内**，用于对1.6版数据库进行数据备份、恢复，以及表结构导出等操作。**【小心！taosdump1.6和2.0的参数不相同】**

【提示】如果导入导出表结构的数量超过10万张，建议开启tmux，在tmux里运行taosdump，避免因网络连接中断，导致运行终止。

```shell
$ ./taosdump16 --help

Usage: taosdump16 [OPTION...] dbname [tbname ...]
  or:  taosdump16 [OPTION...] --databases dbname ...
  or:  taosdump16 [OPTION...] --all-databases
  or:  taosdump16 [OPTION...] -i inpath
  or:  taosdump16 [OPTION...] -o outpath

  -h, --host=HOST            Server host dumping data from. Default is
                             localhost.
  -p, --password=PASSWORD    User password to connect to server. Default is
                             taosdata.
  -P, --port=PORT            Port to connect
  -q, --mysqlFlag=MYSQLFLAG  mysqlFlag, Default is 0
  -u, --user=USER            User name used to connect to server. Default is
                             root.
  -v, --cversion=CVERION     client version
  -c, --config=CONFIG_DIR    Configure directory. Default is
                             /etc/taos/taos.cfg.
  -e, --encode=ENCODE        Input file encoding.
  -i, --inpath=INPATH        Input file path.
  -o, --outpath=OUTPATH      Output file path.
  -A, --all-databases        Dump all databases.
  -B, --databases            Dump assigned databases
  -a, --allow-sys            Allow to dump sys database
  -E, --end-time=END_TIME    End time to dump.
  -M, --with-property        Dump schema with properties.
  -N, --data-batch=DATA_BATCH   Number of data point per insert statement.
                             Default is 1.
  -s, --schemaonly           Only dump schema.
  -S, --start-time=START_TIME   Start time to dump.
  -t, --thread_num=THREAD_NUM   Number of thread for dump in file. Default is
                             5.
  -T, --table-batch=TABLE_BATCH   Number of table dumpout into one output file.
                             Default is 1.
  -?, --help                 Give this help list
      --usage                Give a short usage message
  -V, --version              Print program version

Mandatory or optional arguments to long options are also mandatory or optional
for any corresponding short options.

Report bugs to <support@taosdata.com>.
```

导出testdb数据库所有表结构，每10000张表一个sql文件，10个线程并发，其他为默认参数：

```shell
$ ./taosdump16 -s -T 10000 -t 10 testdb
$ ./taosdump16 -h 192.168.26.11 -o /opt/taos/dump_schema -u root -p taosdata -B power_stations_slsd -S 0 -E 1604113919000 -t 500 -s -T 8
./taosdump16 -o ./sch16/ -p root123 -B sdy_iot_platform_history -s -T 10000 -t 10
```

将在当前目录下导出若干.sql文件。



#### taosdump v2.0

**该工具建议运行在td_dump_node的dockers容器内**，用于对2.0版数据库进行数据备份、恢复，以及表结构导入等操作。

【提示】如果导入导出表结构的数量超过10万张，建议开启tmux，在tmux里运行taosdump，避免因网络连接中断，导致运行终止。

```shell
$ ./taosdump20 --help
Usage: taosdump20 [OPTION...] dbname [tbname ...]
  or:  taosdump20 [OPTION...] --databases dbname ...
  or:  taosdump20 [OPTION...] --all-databases
  or:  taosdump20 [OPTION...] -i inpath
  or:  taosdump20 [OPTION...] -o outpath

  -h, --host=HOST            Server host dumping data from. Default is
                             localhost.
  -p, --password=PASSWORD    User password to connect to server. Default is
                             taosdata.
  -P, --port=PORT            Port to connect
  -q, --mysqlFlag=MYSQLFLAG  mysqlFlag, Default is 0
  -u, --user=USER            User name used to connect to server. Default is
                             root.
  -v, --cversion=CVERION     client version
  -c, --config=CONFIG_DIR    Configure directory. Default is
                             /etc/taos/taos.cfg.
  -e, --encode=ENCODE        Input file encoding.
  -i, --inpath=INPATH        Input file path.
  -o, --outpath=OUTPATH      Output file path.
  -A, --all-databases        Dump all databases.
  -B, --databases            Dump assigned databases
  -a, --allow-sys            Allow to dump sys database
  -E, --end-time=END_TIME    End time to dump.
  -M, --with-property        Dump schema with properties.
  -N, --data-batch=DATA_BATCH   Number of data point per insert statement.
                             Default is 1.
  -s, --schemaonly           Only dump schema.
  -S, --start-time=START_TIME   Start time to dump.
  -t, --table-batch=TABLE_BATCH   Number of table dumpout into one output file.
                             Default is 1.
  -T, --thread_num=THREAD_NUM   Number of thread for dump in file. Default is
                             5.
  -?, --help                 Give this help list
      --usage                Give a short usage message
  -V, --version              Print program version

Mandatory or optional arguments to long options are also mandatory or optional
for any corresponding short options.

Report bugs to <support@taosdata.com>.
```

将之前v1.6导出的表结构，导入到testdb数据库，集群firstEP的fqdn为tdmi1，sql文件位于/home/test/dump，10个线程并发，其他为默认参数：

```shell
$ ./taosdump20 -h tdmi1 -i /home/test/dump -t 10 testdb
```



#### taosmigrate v1.6

**该工具依次运行在td1.6_node<1...n>的dockers容器内**，用于将1.6版的数据文件迁移到新部署环境，让同版本TDengine可以在新环境下启动时能正常访问数据文件。

主要修改项目是将集群内的所有数据节点Dnode的旧IP地址，改为新环境下的IP地址。

**【注意】**

**1. 在docker内启动迁移的环境，必须到dockers容器内进行迁移，才能创建正确的数据文件。**

**2. 迁移时，先将docker文件夹内容映射到docker容器内，command设为bash。迁移完成后，再将command修改为taosd，重新启动docker-compose，才能正常访问迁移后的数据。**

建议在Windows 10下面的WSL中允许该工具，支持字符删除操作。

以前文假设为例，数据文件位于/home/test/dump，集群为双节点，原IP地址为192.168.1.101/102，新IP地址为10.0.0.81/82

```shell
$ ./taosmigrate16
Welcome to use the TDengine data migrate tool. Please make sure
to run this tool on the machine the data is migrated to, and
follow the instructions.

Please enter the data directory (it is /var/lib/taos by default): /home/test/dump
Please enter the number of nodes you want to migrate, or enter a number <= 0 to skip IP modification: 2

Please enter the DNODE 0 info:
>> Enter the old public IP: 192.168.1.101
>> Enter the old private IP: 192.168.1.101
>> Enter the new public IP: 10.0.0.81
>> Enter the new private IP: 10.0.0.81

Please enter the DNODE 1 info:
>> Enter the old public IP: 192.168.1.102
>> Enter the old private IP: 192.168.1.102
>> Enter the new public IP: 10.0.0.82
>> Enter the new private IP: 10.0.0.82
********************** Mod Info ******************************
* Data directory: /home/test/dump
* Number of nodes: 2
*
* Node 1:
*     old publicIp:192.168.1.101    =====>  new publicIp:10.0.0.81
*     old privateIp:192.168.1.101   =====>  new privateIp:10.0.0.81
*
* Node 2:
*     old publicIp:192.168.1.102    =====>  new publicIp:10.0.0.82
*     old privateIp:192.168.1.102   =====>  new privateIp:10.0.0.82
**************************************************************
Start to process mgmt files in rootDir:/home/test/dump
```



#### taosmigrate v2.0

**该工具依次运行在td2.0_node<1...n>的dockers容器内**，将通过taosDumpTunnel转移过来的数据，修改到新的部署环境。

```shell
$ ./taosmigrate20 -?
Usage: taosmigrate20 [OPTION...]

  -r data dir                data dir
  -d dnodeId                 dnode id
  -f fqdn                    dnode fqdn
  -p port                    dnode port
  -g multi dnodes            multi dnode info, e.g. "2 7030 fqdn1, 3 8030
                             fqdn2"
  -?, --help                 Give this help list
      --usage                Give a short usage message
```

将之前taosDumpTunnel转移来的数据，位于/home/test/taosb/data，进行原地重新部署，双节点集群，目标参数为：

dnodeID 1	port 7030	fqdn td1

dnodeID 2 	port 7030	fqdn td2

其中dnodeID要到原系统里面，通过show vgroups获得。

```shell
$ ./taosmigrate20 -r /home/test/taosb/data -g "1 7030 td1, 2 7030 td2"
```



#### taosDumpTunnel

**该工具运行在taos_dump_node的dockers容器内**，将1.6的TDengine运行系统中批量读取数据，写入2.0的TDengine运行系统中。

**【为保证数据迁移的可靠，建议带super-table指定超级表，依次转移。建议使用脚本，具体参见脚本transfer_data.sh】**

**【提示】务必在tmux里运行taosDumpTunnel/transfer_data.sh，避免因网络连接中断，导致运行终止。**

该工具通过RESTful接口访问目标TDengine系统。

```shell
$ ./taosDumpTunnel --help
Usage of ./taosDumpTunnel:
  -batch int
        batch size per dump insert (default 100)
  -create-schema
        create schema before dumping data (default true)
  -db string
        database name to dump
  -dest-host string
        data dest TDengine host (default "127.0.0.1")
  -dest-pass string
        data dest TDengine password (default "taosdata")
  -dest-port int
        data dest TDengine port (default 7011)
  -dest-user string
        data dest TDengine user (default "root")
  -etime int
        end time to dump (included)
  -log-on-console
        if print log on console (default true)
  -schema-only
        only dump schema
  -src-host string
        data source TDengine host (default "127.0.0.1")
  -src-pass string
        data source TDengine password (default "taosdata")
  -src-port int
        data source TDengine port
  -src-user string
        data source TDengine user (default "root")
  -stime int
        start time to dump (not included) (default 1)
  -super-table string
        super table name to dump
  -threads int
        threads to do dump job (default 5)
```

将1.6的TDengine系统，IP地址10.0.0.81，数据库testdb，转移到2.0的TDengine系统，fqdn为10.0.0.35，并发线程10个，批处理数200，目标TDengine端口6041，不生成表结构，转移超级表stb001的数据：

```shell
$ ./taosDumpTunnel -db=testdb -src-host=10.0.0.81 -dest-host=10.0.0.35 -threads=10 -batch=200 -dest-port=6041 -create-schema=false -super-table=stb001
```

【提示】设置为不生成表结构的原因是，在使用taosDumpTunnel转移数据之前，已通过taosdump20将表结构事先导入。去掉生成表结构，将极大加快数据导入速度。





## 相关工具

#### Docker & Docker swarm

##### Ubuntu安装Docker

https://blog.csdn.net/u010889616/article/details/80170767

##### CentOS 安装docker

######     step 1: 安装必要的一些系统工具
​     yum install -y yum-utils device-mapper-persistent-data lvm2 
######     Step 2: 添加软件源信息
​    yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo

​    或  yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo

######     Step 3: 更新并安装 Docker-CE 
​    yum makecache fast 
​    yum -y install docker-ce 

######     Step 4: 开启Docker服务 
​    service docker start

##### Centos7中离线安装Docker CE最新版

https://www.cnblogs.com/songxingzhu/p/10651197.html
**必须先删除旧版本**
**yum remove docker docker-common docker-selinux docker-client**
第6步之前需要安装第5步内容 yum install -y yum-utils device-mapper-persistent-data lvm2
第14步报错，需要手工安装两个包：deltarpm和python-dletarpm
rpm -ivh deltarpm-xxxxx
rpm -ivh python-deltarpm-xxxxx

##### Docker-compose安装

https://www.cnblogs.com/zhi-leaf/p/12090456.html

##### Docker 手动迁移镜像

https://www.cnblogs.com/anliven/p/6759585.html

##### Docker Swarm部署

   1. 确认所有成员节点的docker --version都一致

   2. docker swarm init 创建swarm

   3. 在成员机上执行  docker swarm join --token SWMTKN-1-5h1csmm7sco7qc0z85a3h85xplyscoyplplnwyq6yqr1j50qn9-71tj9w548abni6caojnrbe1lh 10.2.41.232:2377

   4. docker node ls

   5. docker network create -d overlay --attachable --subnet 172.27.0.0/24 taos_update_net

   6. docker network ls

   7. 在管理节点上，将成员节点提升为管理节点   docker node promote uyy3f5aiwebmc09klxs754x0h

      **以上，即已创建一外部网络taos_update_net，子网172.27.0.0/24**

   8. docker swarm leave --force  管理节点退出swarm，每个成员节点均执行

##### Docker-compose命令

docker-compose -h                           # 查看帮助
docker-compose up                           # 创建并运行所有容器
docker-compose up -d                        # 创建并后台运行所有容器
docker-compose -f docker-compose.yml up -d  # 指定模板
docker-compose down                         # 停止并删除容器、网络、卷、镜像。
docker-compose logs       # 查看容器输出日志
docker-compose pull       # 拉取依赖镜像
dokcer-compose config     # 检查配置
dokcer-compose config -q  # 检查配置，有问题才有输出
docker-compose restart   # 重启服务
docker-compose start     # 启动服务
docker-compose stop      # 停止服务

#### tmux

命令行的典型使用方式是，打开一个终端窗口（terminal window，以下简称"窗口"），在里面输入命令。用户与计算机的这种临时的交互，称为一次"会话"（session） 。

会话的一个重要特点是，窗口与其中启动的进程是连在一起的。打开窗口，会话开始；关闭窗口，会话结束，会话内部的进程也会随之终止，不管有没有运行完。

一个典型的例子就是，SSH 登录远程计算机，打开一个远程窗口执行命令。这时，网络突然断线，再次登录的时候，是找不回上一次执行的命令的。因为上一次 SSH 会话已经终止了，里面的进程也随之消失了。

为了解决这个问题，会话与窗口可以"解绑"：窗口关闭时，会话并不终止，而是继续运行，等到以后需要的时候，再让会话"绑定"其他窗口。

Tmux 是将会话与窗口的"解绑"工具，将它们彻底分离。

1. 它允许在单个窗口中，同时访问多个会话。这对于同时运行多个命令行程序很有用。

2. 它可以让新窗口"接入"已经存在的会话。

3. 它允许每个会话有多个连接窗口，因此可以多人实时共享会话。

4. 它还支持窗口任意的垂直和水平拆分。

**tmux new -s <session-name>**

**tmux ls**  

**tmux detach**

**tmux attach -t <session-name>**

**tmux switch -t <session-name>**

所有快捷键都要通过前缀键唤起，默认的前缀键是`Ctrl+b`，常用快捷键有：

**%** 							划分左右两个窗格

**“** 							  划分上下两个窗格

<arrow key> 	  光标切换到其他窗格

**x** 							  关闭当前窗格

**d**							   Detach当前会话

**!** 							   将当前窗格拆分成一个独立窗口

**z** 							  当前窗格全屏显示，再按一次返回原来大小

ctrl+<arrow key> 按箭头方向调整窗格大小

#### 客制化后的快捷键  ubuntu@taosdata.com:~/boxiao/tmux.conf

detach tmux session：<Ctrl-a>d (未配置<Ctrl-b>d)

横向分屏：<Ctrl-a>s (未配置<Ctrl-b>")

纵向分屏：<Ctrl-a>v (未配置<Ctrl-b>%)

打开新的窗口：<Ctrl-a>c (未配置<Ctrl-b>c)

聚焦上panel：<Ctrl-a>k 或<Ctrl-a><UpArrow> (未配置<Ctrl-b><UpArrow>)

聚焦下panel：<Ctrl-a>j 或<Ctrl-a><DownArrow> (未配置<Ctrl-b><DownArrow>)

聚焦左panel：<Ctrl-a>h 或<Ctrl-a><LeftArrow> (未配置<Ctrl-b><LeftArrow>)

聚焦右panel：<Ctrl-a>l 或<Ctrl-a><RightArrow> (未配置<Ctrl-b><RightArrow>)

聚焦下个窗口：<Ctrl-a>n (未配置<Ctrl-b>n)

聚焦上个窗口：<Ctrl-a>p (未配置<Ctrl-b>p)

全屏/关闭全屏（toggle）当前窗口：<Ctrl-a>z (未配置<Ctrl-b>z)

#### Glances

建议安装glances来对服务器运行状态进行监控。除可监控CPU外，还可监控每块磁盘IO吞吐、每个网口包括虚拟网口的入站、出站流量。

方便即时掌握计算机运行状态。



## 其他工具

中间转存站 taosdata.com

log.sh 登录docker容器脚本

start-taosd.sh 启动静态编译版本taosd的守护脚本

transfer_data.sh 执行taosDumpTunnel，逐个按超级表进行数据导入导出的批处理脚本

#### taosdemo 样例数据库导入及网络诊断



#### lowa 数据导入与并发

由可执行文件lowa，及insert.json, query.json subscribe.json组成。

建议每个实例负责一个超级表的写入、一个查询场景、一个订阅场景。可以启动多个lowa，并行执行多个任务。

一个lowa运行环境建议放在一个文件夹内，一般由lowa，一个json文件，一个或多个csv文件组成。

```json
{

    "host": "127.0.0.1",			#写入的服务器fqdn
    "port": 6030,							#端口号
    "user": "root",
    "password": "taosdata",
    "thread_count": 1,				#并发线程数
    "databases": [{
        "dbinfo": {
            "name": "db01",		#数据库名
            "replica": 1,
            "days": 10,
            "cache": 16,
            "blocks": 8,
            "precision": "ms",
            "update": 0,								#允许更新，新值覆盖旧值
            "maxtablesPerVnode": 1000		#每个vnode最大子表数
        },
        "super_tables": [{
            "name": "stb01",
            "childtable_count": 10,					#子表数
            "childtable_prefix": "stb01_",
            "auto_create_table": "no",			#如先建子表再插入数据，则为no；如插入数据自动建表，yes;如无需创建子表，null 
            "data_source": "rand",					#rand，随机生成；sample，用sample_file循环导入
            "insert_mode": "taosc",					#taosc 或 restful
            "insert_rate": 0,								# 0 - 全速插入；>0, 每表每秒插入的条数
            "insert_rows": 0,								#每表总插入条数，0 - 不插入数据
            "timestamp_step": 1000,					#每条记录时间戳步长，ms
            "start_timestamp": "2020-10-01 00:00:00.000",	#起始时间戳
            "sample_format": "csv",
            "sample_file": "/home/data/sample.csv",
            "tags_file": "",								#空，tag值随机生成；非空，从该文件循环导入
            "columns": [{										#表结构
                "type": "SMALLINT"
            }, {
                "type": "BOOL"
            }, {
                "type": "BINARY",
                "len": 6
            }],															
            "tags": [{											#tag结构
                "type": "INT"
            },{
                "type": "BINARY",
                "len": 4
            }]
        }]
    }]
}
```

#### 获得客户端去重清单

**grep "new TCP connection" ./taosdlog.* | sed -e "s/\..* from / /"|sed -e "s/,.$//"|sed -e "s/:[0-9]$//"|sort -r|uniq -f 2|sort -k 3 -r|uniq -f 2**

11/16 03:58:14 172.17.2.2
11/15 02:58:14 172.17.1.2
11/18 14:38:10 172.17.0.2

